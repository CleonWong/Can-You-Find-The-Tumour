{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to build Unet using TensorFlow\n",
    "\n",
    "**Proposed pipeline:**\n",
    "1. **Data loading pipeline**\n",
    "    1. `splitXYPaths()` - Gets the paths of X and Y images.\n",
    "    2. `matchXYPaths()` - Matches each X path with its corresponding Y path.\n",
    "2. **Model**\n",
    "    1. asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Non-essential\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Data loading pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"../data/preprocessed/Mass/Train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitXYPaths(input_path, x_identifier, y_identifier, img_format):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function recursively iterates through\n",
    "    `input_path`, extracts and splits the paths of X\n",
    "    and Y images.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_path : {str}\n",
    "        The relative (or absolute) path of the folder\n",
    "        that contains the X and Y images.\n",
    "    x_identifier : {str}\n",
    "        A (sub)string that uniquely identifies a path\n",
    "        that belongs to an X image (as opposed to a Y\n",
    "        image a.k.a label). i.e. A X image pat is sure\n",
    "        to contain this substring.\n",
    "    y_identifier \": {str}\n",
    "        A (sub)string that uniquely identifies a path\n",
    "        that belonds to a Y image (label). i.e. A Y\n",
    "        image path is sure to contain this substring.\n",
    "    img_format : {str}\n",
    "        E.g. \".jpg\", \".png\", etc.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    x_paths_list : {list}\n",
    "        List of X image paths.\n",
    "    y_paths_list : {list}\n",
    "        List of Y image paths.\n",
    "    unidentified_paths_list : {list}\n",
    "        List of image paths that are neither X or Y\n",
    "        images.\n",
    "    \"\"\"\n",
    "    \n",
    "    x_paths_list = []\n",
    "    y_paths_list = []\n",
    "    unidentified_paths_list = []\n",
    "    \n",
    "    for curdir, dirs, files in os.walk(input_path):\n",
    "        \n",
    "        dirs.sort()\n",
    "        files.sort()\n",
    "        \n",
    "        for f in files:\n",
    "            \n",
    "            if f.endswith(img_format):\n",
    "                \n",
    "                if x_identifier in f:\n",
    "                    x_paths_list.append(os.path.join(curdir, f))\n",
    "                elif y_identifier in f:\n",
    "                    y_paths_list.append(os.path.join(curdir, f))\n",
    "                else:\n",
    "                    unidentified_paths_list.append(os.path.join(curdir, f))\n",
    "    \n",
    "    return x_paths_list, y_paths_list, unidentified_paths_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_paths_list, y_paths_list, _ = SplitXYPaths(input_path=input_path,\n",
    "                                             x_identifier=\"FULL\",\n",
    "                                             y_identifier=\"MASK\",\n",
    "                                             img_format=\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_paths_list))\n",
    "print(len(y_paths_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchXYPaths(x_paths_list, y_paths_list):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function matches an X image path with its\n",
    "    corresponding Y image path.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_paths_list : {list}\n",
    "        List of X image paths.\n",
    "    y_paths_list : {list}\n",
    "        List of Y image paths.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    img_paths_dict : {dict}\n",
    "        A dict where (key, value) = (path of X image, \n",
    "        path of correcponding Y image).\n",
    "        \n",
    "        Note: \n",
    "        This implies that for every X image, there\n",
    "        should only be one corresponding Y image (label).\n",
    "    \"\"\"\n",
    "    \n",
    "    img_paths_dict = {}\n",
    "    \n",
    "    for x_ in x_paths_list:\n",
    "                \n",
    "        # Get patient_id.\n",
    "        substring = x_.split(\"_P_\")[-1]\n",
    "        subsubstring = substring.split(\"_\")\n",
    "        patient_id = \"P_\" + subsubstring[0]\n",
    "\n",
    "        # Get image view (i.e. LEFT or RIGHT).\n",
    "        img_view = subsubstring[1]\n",
    "\n",
    "        # Get description (i.e. CC or MLO).\n",
    "        cc_mlo = subsubstring[2]\n",
    "\n",
    "        # Get unique identifier.\n",
    "        uniq_str = \"_\".join([patient_id, img_view, cc_mlo])\n",
    "        \n",
    "        # Find corresponding y image path(s).\n",
    "        y_ = [y for y in y_paths_list if uniq_str in y]\n",
    "        \n",
    "        img_paths_dict[x_] = y_\n",
    "    \n",
    "    return img_paths_dict\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths_dict = MatchXYPaths(x_paths_list=x_paths_list, y_paths_list=y_paths_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in img_paths_dict.items():\n",
    "    \n",
    "    if len(v) > 1:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractData(input_path):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function reads all the images from the given\n",
    "    `input_path` and saves them in a list. The lists\n",
    "    of X_ and Y_ are returned.\n",
    "    \n",
    "    Note: \n",
    "    `input_path` is expected to contain both the X\n",
    "    images and the Y images (labels).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_path : {str}\n",
    "        The relative (or absolute) path of the folder\n",
    "        that contains the X and Y images.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X_: {list}\n",
    "        A list that contains all the X images as numpy\n",
    "        arrays.\n",
    "    Y_: {list}\n",
    "        A list that contains all the Y images (labels)\n",
    "        as numpy arrays.\n",
    "    \"\"\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Buidling the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Loading pre-trained model as `down_stack` part of the U-net.\n",
    "\n",
    "**References:**\n",
    "- [`tf.keras.applications.VGG16` documentation](https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG16)\n",
    "- [TF's image segmentation tutorial](https://www.tensorflow.org/tutorials/images/segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model.\n",
    "def VGGBaseModel(input_shape):\n",
    "    \n",
    "    base_model = tf.keras.applications.VGG16(include_top=False,\n",
    "                                             weights=\"imagenet\", # Load weights pre-trained on ImageNet\n",
    "                                             input_shape=input_shape) # Can be changed, minimum is (200, 200, 3)\n",
    "    \n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model = VGGBaseModel(input_shape=(448, 448, 3))\n",
    "\n",
    "print(type(base_model))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of layer names.\n",
    "layer_names = [layer.name for layer in base_model.layers]\n",
    "\n",
    "# Get layer outputs.\n",
    "layer_outputs = [base_model.get_layer(layer_name).output for layer_name in layer_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(base_model.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the feature extraction model.\n",
    "down_stack = tf.keras.Model(inputs=base_model.input,\n",
    "                            outputs=layer_outputs,\n",
    "                            name=\"down_stack\")\n",
    "\n",
    "# Freeze all layers.\n",
    "down_stack.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "down_stack.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layers_info = [(layer, layer.name, layer.trainable) for layer in base_model.layers]\n",
    "pd.DataFrame(data=layers_info, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# REDO!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upstack\n",
    "\n",
    "Comments:\n",
    "- Still missing the concatenation layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2DBlock(keras.layers.Layer):\n",
    "    def __init__(self, name, filters, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", activation=\"relu\"):\n",
    "\n",
    "        \"\"\"\n",
    "        The init function of Conv2DBlock. This initialises the convolutional\n",
    "        block representing the following network:\n",
    "\n",
    "            - Conv2D --> Activation function --> Batch Norm (not yet).\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        super(Conv2DBlock, self).__init__(name=name)\n",
    "\n",
    "        # Conv layer\n",
    "        self.conv = keras.layers.Conv2D(\n",
    "            name=name, filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, activation=activation\n",
    "        )\n",
    "        \n",
    "        # Batch Normalisation layer\n",
    "#         self.bn = layers.BatchNormalization()\n",
    "        \n",
    "    def call(self, input_tensor):\n",
    "        \n",
    "        x = self.conv(input_tensor)\n",
    "#         x = self.bn(x, training=training)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2DTransBlock(keras.layers.Layer):\n",
    "    def __init__(self, name, filters, kernel_size=(3, 3), strides=(2, 2), padding=\"same\", activation=None):\n",
    "\n",
    "        \"\"\"\n",
    "        The init function of Conv2DTransBlock. This initialises the convolutional\n",
    "        block representing the trnaspose convolution operation.\n",
    "        \n",
    "        Default is to increase the width and the height of the tensor by 2x.\n",
    "        \"\"\"\n",
    "\n",
    "        super(Conv2DTransBlock, self).__init__(name=name)\n",
    "        \n",
    "        # Conv2dTranspose layer\n",
    "        self.convT = keras.layers.Conv2DTranspose(name=name,\n",
    "                                                  filters=filters,\n",
    "                                                  kernel_size=kernel_size,\n",
    "                                                  strides=strides,\n",
    "                                                  padding=padding,\n",
    "                                                  activation=activation)\n",
    "        \n",
    "    def call(self, input_tensor):\n",
    "        \n",
    "        x = self.convT(input_tensor)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upstack(keras.Model):\n",
    "    \n",
    "    def __init__(self, input_tensor_shape, in_filters, out_filters, **kwargs):\n",
    "\n",
    "        super(Upstack, self).__init__(**kwargs)\n",
    "        \n",
    "        # =====================\n",
    "        # Defining model layers\n",
    "        # =====================\n",
    "        \n",
    "        # BLOCK 1\n",
    "        # -------\n",
    "        # input shape = (x, x, in_filters)\n",
    "        self.T_conv_1 = Conv2DTransBlock(name=\"T_conv_1\", filters=in_filters)\n",
    "        # output, input shape = (2x, 2x, in_filters)\n",
    "        self.conv_1a = Conv2DBlock(name=\"conv_1a\", filters=in_filters)\n",
    "        self.conv_1b = Conv2DBlock(name=\"conv_1b\", filters=in_filters)\n",
    "        self.conv_1c = Conv2DBlock(name=\"conv_1c\", filters=in_filters)\n",
    "        # output shape = (2x, 2x, in_filters)\n",
    "        \n",
    "        # BLOCK 2\n",
    "        # -------\n",
    "        # input shape = (2x, 2x, in_filters)\n",
    "        self.T_conv_2 = Conv2DTransBlock(name=\"T_conv_2\", filters=in_filters)\n",
    "        # output, input shape = (4x, 4x, in_filters)\n",
    "        self.conv_2a = Conv2DBlock(name=\"conv_2a\", filters=in_filters)\n",
    "        self.conv_2b = Conv2DBlock(name=\"conv_2b\", filters=in_filters)\n",
    "        self.conv_2c = Conv2DBlock(name=\"conv_2c\", filters=in_filters)\n",
    "        # output shape = (4x, 4x, in_filters)\n",
    "        \n",
    "        # BLOCK 3\n",
    "        # -------\n",
    "        # input shape = (4x, 4x, in_filters)\n",
    "        self.T_conv_3 = Conv2DTransBlock(name=\"T_conv_3\", filters=in_filters / 2)\n",
    "        # output, input shape = (8x, 8x, in_filters / 2)\n",
    "        self.conv_3a = Conv2DBlock(name=\"conv_3a\", filters=in_filters / 2)\n",
    "        self.conv_3b = Conv2DBlock(name=\"conv_3b\", filters=in_filters / 2)\n",
    "        self.conv_3c = Conv2DBlock(name=\"conv_3c\",filters=in_filters / 2)\n",
    "        # output shape = (8x, 8x, in_filters / 2)\n",
    "        \n",
    "        # BLOCK 4\n",
    "        # -------\n",
    "        # input shape = (8x, 8x, in_filters / 2)\n",
    "        self.T_conv_4 = Conv2DTransBlock(name=\"T_conv_4\", filters=in_filters / 4)\n",
    "        # output, input shape = (16x, 16x, in_filters / 4)\n",
    "        self.conv_4a = Conv2DBlock(name=\"conv_4a\", filters=in_filters / 4)\n",
    "        self.conv_4b = Conv2DBlock(name=\"conv_4b\", filters=in_filters / 4)\n",
    "        # output shape = (16x, 16x, in_filters / 4)\n",
    "        \n",
    "        # BLOCK 5\n",
    "        # -------\n",
    "        # input shape = (16x, 16x, in_filters / 4)\n",
    "        self.T_conv_5 = Conv2DTransBlock(name=\"T_conv_5\", filters=in_filters / 8)\n",
    "        # output, input shape = (32x, 32x, in_filters / 8)\n",
    "        self.conv_5a = Conv2DBlock(name=\"conv_5a\", filters=in_filters / 8)\n",
    "        self.conv_5b = Conv2DBlock(name=\"conv_5b\", filters=in_filters / 8)\n",
    "        # output shape = (32x, 32x, in_filters / 8)\n",
    "        \n",
    "        # FINAL CONV\n",
    "        # ----------\n",
    "        # input shape = (32x, 32x, in_filters / 8)\n",
    "        self.final_conv = Conv2DBlock(name=\"final_conv\", filters=out_filters)\n",
    "        # input shape = (32x, 32x, out_filters)\n",
    "\n",
    "        # Other parameters\n",
    "        self.input_tensor_shape = input_tensor_shape\n",
    "        \n",
    "    def call(self, input_tensor):\n",
    "\n",
    "        x = self.T_conv_1(input_tensor)\n",
    "        x = self.conv_1a(x)\n",
    "        x = self.conv_1b(x)\n",
    "        x = self.conv_1c(x)\n",
    "        \n",
    "        x = self.T_conv_2(x)\n",
    "        x = self.conv_2a(x)\n",
    "        x = self.conv_2b(x)\n",
    "        x = self.conv_2c(x)\n",
    "        \n",
    "        x = self.T_conv_3(x)\n",
    "        x = self.conv_3a(x)\n",
    "        x = self.conv_3b(x)\n",
    "        x = self.conv_3c(x)\n",
    "        \n",
    "        x = self.T_conv_4(x)\n",
    "        x = self.conv_4a(x)\n",
    "        x = self.conv_4b(x)\n",
    "        \n",
    "        x = self.T_conv_5(x)\n",
    "        x = self.conv_5a(x)\n",
    "        x = self.conv_5b(x)\n",
    "        \n",
    "        x = self.final_conv(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    # To allow printing of Output Shape in model.summary().\n",
    "    def model(self):\n",
    "        x = keras.Input(name=\"from_downstack\", shape=self.input_tensor_shape)\n",
    "        x = keras.Model(inputs=[x], outputs=self.call(x), name=\"Upstack\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Upstack(input_tensor_shape=(14, 14, 512), in_filters=512, out_filters=3, name=\"Upstack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [np.random.uniform(low=0, high=1.0, size=(14, 14, 512)) for i in range(10)]\n",
    "y_train = [np.random.randint(low=0, high=2, size=(448, 448, 3)) for i in range(10)]\n",
    "\n",
    "def GenerateInputs(X, y):\n",
    "    for i in range(len(X)):\n",
    "        X_input = X[i].reshape(1, 14, 14, 512)\n",
    "        y_input = y[i].reshape(1, 448, 448, 3)\n",
    "        yield (X_input,y_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "5/5 - 10s - loss: 4.9698 - accuracy: 0.3682\n",
      "Epoch 2/2\n",
      "5/5 - 11s - loss: 1.9016 - accuracy: 0.2505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x150e67bb0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(GenerateInputs(X=x_train, y=y_train), batch_size=1, steps_per_epoch = 5, epochs=2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Upstack\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 14, 14, 512)]     0         \n",
      "_________________________________________________________________\n",
      "T_conv_1 (Conv2DTransBlock)  (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv_1a (Conv2DBlock)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv_1b (Conv2DBlock)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv_1c (Conv2DBlock)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "T_conv_2 (Conv2DTransBlock)  (None, 56, 56, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv_2a (Conv2DBlock)        (None, 56, 56, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv_2b (Conv2DBlock)        (None, 56, 56, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv_2c (Conv2DBlock)        (None, 56, 56, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "T_conv_3 (Conv2DTransBlock)  (None, 112, 112, 256)     1179904   \n",
      "_________________________________________________________________\n",
      "conv_3a (Conv2DBlock)        (None, 112, 112, 256)     590080    \n",
      "_________________________________________________________________\n",
      "conv_3b (Conv2DBlock)        (None, 112, 112, 256)     590080    \n",
      "_________________________________________________________________\n",
      "conv_3c (Conv2DBlock)        (None, 112, 112, 256)     590080    \n",
      "_________________________________________________________________\n",
      "T_conv_4 (Conv2DTransBlock)  (None, 224, 224, 128)     295040    \n",
      "_________________________________________________________________\n",
      "conv_4a (Conv2DBlock)        (None, 224, 224, 128)     147584    \n",
      "_________________________________________________________________\n",
      "conv_4b (Conv2DBlock)        (None, 224, 224, 128)     147584    \n",
      "_________________________________________________________________\n",
      "T_conv_5 (Conv2DTransBlock)  (None, 448, 448, 64)      73792     \n",
      "_________________________________________________________________\n",
      "conv_5a (Conv2DBlock)        (None, 448, 448, 64)      36928     \n",
      "_________________________________________________________________\n",
      "conv_5b (Conv2DBlock)        (None, 448, 448, 64)      36928     \n",
      "_________________________________________________________________\n",
      "final_conv (Conv2DBlock)     (None, 448, 448, 3)       1731      \n",
      "=================================================================\n",
      "Total params: 22,568,195\n",
      "Trainable params: 22,568,195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.model().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Downstack_VGG16(keras.Model):\n",
    "    \n",
    "    def __init__(self, _input_shape, _include_top=False, _weights=\"imagenet\", **kwargs):\n",
    "        super(Downstack_VGG16, self).__init__(**kwargs)\n",
    "        self.base_vgg16 = keras.applications.VGG16(include_top=_include_top, weights=_weights, input_shape=_input_shape)\n",
    "        \n",
    "        # Parameters\n",
    "        self._input_shape = _input_shape\n",
    "        \n",
    "    def call(self, input_tensor):\n",
    "        x = self.base_vgg16(input_tensor)\n",
    "        return x\n",
    "        \n",
    "    def model(self):\n",
    "        x = keras.Input(name=\"input_layer\", shape=self._input_shape)\n",
    "        x = keras.Model(inputs=[x], outputs=self.call(x), name=\"Downstack_VGG16\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "downstack = Downstack_VGG16(_input_shape=(448, 448, 3), _include_top=False, _weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 448, 448, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 448, 448, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 448, 448, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 224, 224, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 224, 224, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 112, 112, 256)     295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 112, 112, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 112, 112, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 56, 56, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 56, 56, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 56, 56, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "downstack.base_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet_VGG16(keras.Model):\n",
    "    \n",
    "    def __init__(self, input_tensor_shape, _include_top, _weights, **kwargs):\n",
    "        super(Unet_VGG16, self).__init__(**kwargs)\n",
    "#         self.downstack = Downstack_VGG16(_input_shape=input_tensor_shape, _include_top=False, _weights=\"imagenet\")\n",
    "        self.downstack = keras.applications.VGG16(include_top=_include_top, weights=_weights, input_shape=input_tensor_shape)\n",
    "        self.upstack = Upstack(input_tensor_shape=(14, 14, 512), in_filters=512, out_filters=3, name=\"Upstack\")\n",
    "        \n",
    "        # Parameters\n",
    "        self.input_tensor_shape = input_tensor_shape\n",
    "        \n",
    "    def call(self, input_tensor):\n",
    "        x = self.downstack(input_tensor)\n",
    "        x = self.upstack(x)\n",
    "        return x\n",
    "        \n",
    "    def model(self):\n",
    "        x = keras.Input(name=\"input_layer\", shape=self.input_tensor_shape)\n",
    "        x = keras.Model(inputs=[x], outputs=self.call(x), name=\"Unet_VGG16\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = Unet_VGG16(input_tensor_shape=(448, 448, 3), _include_top=False, _weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [np.random.uniform(low=0, high=1.0, size=(448, 448, 3)) for i in range(10)]\n",
    "y_train = [np.random.randint(low=0, high=2, size=(448, 448, 3)) for i in range(10)]\n",
    "\n",
    "def GenerateInputs(X, y):\n",
    "    for i in range(len(X)):\n",
    "        X_input = X[i].reshape(1, 448, 448, 3)\n",
    "        y_input = y[i].reshape(1, 448, 448, 3)\n",
    "        yield (X_input,y_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "5/5 - 16s - loss: 7.2121 - accuracy: 0.2978\n",
      "Epoch 2/2\n",
      "5/5 - 17s - loss: 7.6245 - accuracy: 0.2532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x151d7afd0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet.fit(GenerateInputs(X=x_train, y=y_train), batch_size=1, steps_per_epoch = 5, epochs=2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Unet_VGG16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     [(None, 448, 448, 3)]     0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Functional)           (None, 14, 14, 512)       14714688  \n",
      "_________________________________________________________________\n",
      "Upstack (Upstack)            (None, 448, 448, 3)       22568195  \n",
      "=================================================================\n",
      "Total params: 37,282,883\n",
      "Trainable params: 37,282,883\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "unet.model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
